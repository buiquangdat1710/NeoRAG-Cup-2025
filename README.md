# üöÄ NeoRAG Cup 2025

## 1. Gi·ªõi thi·ªáu
NeoRAG Cup 2025 l√† cu·ªôc thi h·ªçc thu·∫≠t ‚Äì k·ªπ thu·∫≠t do **Team AI ‚Äì CLB L·∫≠p tr√¨nh ProPTIT** t·ªï ch·ª©c, d√†nh cho c√°c b·∫°n ƒëam m√™ **Tr√≠ tu·ªá nh√¢n t·∫°o (AI)**, **X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)** v√† **K·ªπ thu·∫≠t h·ªá th·ªëng**.  

Ng∆∞·ªùi tham gia s·∫Ω:
- T·ª± thi·∫øt k·∫ø, hi·ªán th·ª±c h√≥a v√† tr√¨nh b√†y m·ªôt **pipeline RAG** (Retrieval-Augmented Generation) v·ªõi domain l√† th√¥ng tin c·ªßa CLB ProPTIT.
- Tr·∫£i nghi·ªám to√†n b·ªô quy tr√¨nh ph√°t tri·ªÉn s·∫£n ph·∫©m AI t·ª´ **√Ω t∆∞·ªüng ‚Üí tri·ªÉn khai ‚Üí demo**.

---

## 2. Th·ªÉ l·ªá & Y√™u c·∫ßu
**Domain:** Th√¥ng tin li√™n quan ƒë·∫øn CLB ProPTIT (l·ªãch s·ª≠, th√†nh vi√™n, ho·∫°t ƒë·ªông, d·ª± √°n, t√†i li·ªáu n·ªôi b·ªô, v.v.)

**Nhi·ªám v·ª•:**
1. Thi·∫øt k·∫ø pipeline RAG ho√†n ch·ªânh (ki·∫øn tr√∫c, c√¥ng ngh·ªá, chi·∫øn l∆∞·ª£c index, retrieval, reranking, generation‚Ä¶).
2. Tri·ªÉn khai code hi·ªán th·ª±c pipeline.
3. Chu·∫©n b·ªã slide thuy·∫øt tr√¨nh m√¥ t·∫£ ki·∫øn tr√∫c, gi·∫£i ph√°p v√† k·∫øt qu·∫£.
4. Ch·∫°y demo h·ªá th·ªëng trong bu·ªïi pitching.

**T√†i nguy√™n BTC cung c·∫•p:**
- B·ªô dataset chu·∫©n v·ªÅ CLB PROPTIT.
- Metrics benchmark: Context Recall, Context Precision, MRR, Hit@k, ‚Ä¶

**H√¨nh th·ª©c d·ª± thi:** C√° nh√¢n.

---

## 3. M·ªëc th·ªùi gian
- **Tu·∫ßn 0:** Ph√°t ƒë·ªông cu·ªôc thi, g·ª≠i dataset & benchmark metrics.
- **Tu·∫ßn 1‚Äì3:** Ho√†n thi·ªán pipeline, code v√† slide.
- **Ng√†y Pitching:**
  - T·ªëi ƒëa **30 ph√∫t** thuy·∫øt tr√¨nh + **10 ph√∫t** Q&A.
  - Ch·∫°y demo code tr·ª±c ti·∫øp (c√≥ th·ªÉ d√πng Streamlit).

---

## 4. Ti√™u ch√≠ ch·∫•m ƒëi·ªÉm
| Ti√™u ch√≠                  | Tr·ªçng s·ªë |
|---------------------------|----------|
| Ki·∫øn tr√∫c pipeline        | 30%      |
| Hi·ªáu nƒÉng benchmark       | 40%      |
| Ch·∫•t l∆∞·ª£ng demo           | 20%      |
| K·ªπ nƒÉng thuy·∫øt tr√¨nh      | 10%      |

---

## 5. Gi·∫£i th∆∞·ªüng
ü•á **Gi·∫£i Nh·∫•t:** 200.000 VNƒê + Gi·∫•y ch·ª©ng nh·∫≠n  
ü•à **Gi·∫£i Nh√¨:** 150.000 VNƒê + Gi·∫•y ch·ª©ng nh·∫≠n  
ü•â **Gi·∫£i Ba:** 100.000 VNƒê + Gi·∫•y ch·ª©ng nh·∫≠n  
üåü **Gi·∫£i Ti·ªÅm NƒÉng:** 50.000 VNƒê + Gi·∫•y ch·ª©ng nh·∫≠n  

---

## 6. ƒê·ªëi t∆∞·ª£ng tham gia
- Th√†nh vi√™n thu·ªôc **Team AI ‚Äì CLB L·∫≠p tr√¨nh ProPTIT**

üìå H√£y s·∫µn s√†ng **s√°ng t·∫°o & b·ª©t ph√°** c√πng NeoRAG Cup 2025!  
üí¨ M·ªçi th·∫Øc m·∫Øc vui l√≤ng comment ho·∫∑c inbox BTC ƒë·ªÉ ƒë∆∞·ª£c gi·∫£i ƒë√°p.

---

## üìä Benchmark

- Trong su·ªët cu·ªôc thi, c√°c b·∫°n s·∫Ω ch·ªâ ƒë∆∞·ª£c cung c·∫•p b·ªô d·ªØ li·ªáu train. B·ªô d·ªØ li·ªáu test s·∫Ω ƒë∆∞·ª£c BTC c√¥ng b·ªë v√†o ng√†y thi cu·ªëi c√πng. D∆∞·ªõi ƒë√¢y l√† benchmark c·ªßa baseline model ‚Äî m·ª•c ti√™u c·ªßa b·∫°n l√† x√¢y d·ª±ng m√¥ h√¨nh c√≥ hi·ªáu nƒÉng v∆∞·ª£t qua ƒë∆∞·ª£c baseline model. 

### **Retrieval ‚Äì Train (100 query)** 
| K  | hit@k | recall@k | precision@k | f1@k | map@k | mrr@k | ndcg@k | context_precision@k | context_recall@k | context_entities_recall@k |
|----|-------|----------|-------------|------|-------|-------|--------|----------------------|------------------|---------------------------|
| 3  | 0.31  | 0.19     | 0.12        | 0.15 | 0.23  | 0.23  | 0.25   | 0.63                 | 0.50             | 0.32                      |
| 5  | 0.46  | 0.28     | 0.10        | 0.15 | 0.23  | 0.27  | 0.31   | 0.56                 | 0.44             | 0.37                      |
| 7  | 0.57  | 0.35     | 0.09        | 0.15 | 0.23  | 0.28  | 0.35   | 0.54                 | 0.40             | 0.38                      |

### **LLM Answer ‚Äì Train (100 query)**
| K  | string_presence@k | rouge_l@k | bleu_4@k | groundedness@k | response_relevancy@k | noise_sensitivity@k |
|----|-------------------|-----------|----------|----------------|----------------------|---------------------|
| 3  | 0.35              | 0.21      | 0.03     | 0.57           | 0.80                 | 0.51                |
| 5  | 0.40              | 0.23      | 0.03     | 0.61           | 0.80                 | 0.53                |
| 7  | 0.41              | 0.22      | 0.04     | 0.64           | 0.80                 | 0.51                |

---

### **Retrieval ‚Äì Test (30 query)**
| K  | hit@k | recall@k | precision@k | f1@k | map@k | mrr@k | ndcg@k | context_precision@k | context_recall@k | context_entities_recall@k |
|----|-------|----------|-------------|------|-------|-------|--------|----------------------|------------------|---------------------------|
| 3  | 0.23  | 0.06     | 0.08        | 0.07 | 0.12  | 0.12  | 0.15   | 0.34                 | 0.32             | 0.11                      |
| 5  | 0.40  | 0.10     | 0.08        | 0.09 | 0.16  | 0.16  | 0.22   | 0.35                 | 0.29             | 0.15                      |
| 7  | 0.47  | 0.13     | 0.08        | 0.10 | 0.17  | 0.17  | 0.24   | 0.31                 | 0.27             | 0.16                      |

### **LLM Answer ‚Äì Test (30 query)**
| K  | string_presence@k | rouge_l@k | bleu_4@k | groundedness@k | response_relevancy@k | noise_sensitivity@k |
|----|-------------------|-----------|----------|----------------|----------------------|---------------------|
| 3  | 0.18              | 0.14      | 0.01     | 0.33           | 0.79                 | 0.68                |
| 5  | 0.16              | 0.15      | 0.01     | 0.30           | 0.79                 | 0.71                |
| 7  | 0.21              | 0.15      | 0.02     | 0.39           | 0.80                 | 0.71                |
